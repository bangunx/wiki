name: Miraheze Wiki Backup → Internet Archive

on:
  # Jadwal bulanan kira-kira jam 00:00 WIB (UTC+7) ≈ 17:00 UTC hari sebelumnya
  schedule:
    - cron: "0 17 30 * *"
  # Bisa dipicu manual
  workflow_dispatch:
    inputs:
      wiki_url:
        description: "Override WIKI_URL (opsional)"
        required: false
        type: string
      archive_id:
        description: "Override ARCHIVE_ID (opsional)"
        required: false
        type: string

permissions:
  contents: read

concurrency:
  group: miraheze-backup
  cancel-in-progress: false

jobs:
  backup:
    runs-on: ubuntu-latest
    timeout-minutes: 360
    env:
      # Default dari repo Variables (bisa dioverride saat manual run)
      WIKI_URL: ${{ inputs.wiki_url || vars.WIKI_URL }}
      ARCHIVE_ID: ${{ inputs.archive_id || vars.ARCHIVE_ID }}
      IA_ACCESS_KEY: ${{ secrets.IA_ACCESS_KEY }}
      IA_SECRET_KEY: ${{ secrets.IA_SECRET_KEY }}

    steps:
      - name: Checkout (optional)
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install CLI deps
        run: |
          python -m pip install --upgrade pip
          pip install wikiteam3 internetarchive

      - name: Prepare workspace
        run: |
          set -euxo pipefail
          mkdir -p work
          cd work
          echo "Target wiki: ${WIKI_URL}"
          # Siapkan cookies bila tersedia
          if [ -n "${{ secrets.COOKIE_TXT_B64 }}" ]; then
            echo "${{ secrets.COOKIE_TXT_B64 }}" | base64 -d > cookies.txt
            echo "Cookies present (private wiki mode)"
          else
            echo "No cookies (public wiki mode)"
          fi

      - name: Run WikiTeam3 dump
        working-directory: work
        shell: bash
        run: |
          set -euxo pipefail
          BASE_CMD="wikiteam3dumpgenerator ${WIKI_URL} --xml --xmlrevisions --images --bypass-cdn-image-compression --force"
          if [ -f cookies.txt ]; then
            ${BASE_CMD} --cookies cookies.txt
          else
            ${BASE_CMD}
          fi

      - name: Package tar.gz
        working-directory: work
        run: |
          set -euxo pipefail
          ITEM="miraheze-backup-$(date +'%Y-%m-%d')"
          mkdir -p package
          shopt -s nullglob
          # Susun isi umum dari WikiTeam3 ke folder package/
          mv pages*.xml package/ || true
          mv siteinfo*.json package/ || true
          if [ -d images ]; then mv images package/; fi
          tar -czf "${ITEM}.tar.gz" -C package .
          echo "ARCHIVE_FILE=${ITEM}.tar.gz" >> $GITHUB_ENV

      - name: Upload to Internet Archive (retry)
        working-directory: work
        env:
          IA_ACCESS_KEY: ${{ secrets.IA_ACCESS_KEY }}
          IA_SECRET_KEY: ${{ secrets.IA_SECRET_KEY }}
        run: |
          set -euxo pipefail
          FILE="${ARCHIVE_FILE}"

          # Env untuk IA CLI (baca S3 keys)
          export IA_S3_ACCESS_KEY="${IA_ACCESS_KEY}"
          export IA_S3_SECRET_KEY="${IA_SECRET_KEY}"

          TITLE="Backup of ${WIKI_URL} ($(date +'%Y-%m-%d'))"
          DESC="Automatic backup of ${WIKI_URL} (XML+images) via GitHub Actions on $(date -u +'%Y-%m-%d %H:%M:%SZ')."
          SUBJECT="miraheze,mediawiki,backup"
          CREATOR="@hadesarchive"

          # Retry sederhana sampai 3x
          n=0
          until [ $n -ge 3 ]
          do
            ia upload "${ARCHIVE_ID}" "${FILE}" \
              --metadata="title:${TITLE}" \
              --metadata="subject:${SUBJECT}" \
              --metadata="creator:${CREATOR}" \
              --metadata="description:${DESC}" \
              --checksum --delete --no-derive && break
            n=$((n+1))
            echo "Upload failed, retry $n/3 after 60s..."
            sleep 60
          done

      - name: Save artifact (secondary backup)
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.ARCHIVE_FILE }}
          path: work/${{ env.ARCHIVE_FILE }}
          retention-days: 14
